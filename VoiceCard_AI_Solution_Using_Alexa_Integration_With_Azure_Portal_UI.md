Yes, you can integrate the "VoiceCard AI" application with Amazon Alexa using the Alexa Skills Kit (ASK) to enable voice-driven credit card quotation functionality, allowing any person to interact with Alexa and perform the same operations as in the previous Java-based solution. Instead of directly calling a toll-free number or simulating a call through a web interface, users can now say, "Alexa, open VoiceCard AI," and Alexa will guide them through the process of generating a credit card quotation ID and handling follow-up questions. This approach leverages Alexa's natural language processing capabilities to provide a seamless voice-driven experience for visually challenged users, aligning with the application's accessibility goals.

We'll adapt the previous Java-based solution (without Copilot Studio, using Azure Portal UI for service setup) to integrate with Alexa. The core functionality (voice interaction, quotation ID generation, database storage, etc.) will remain the same, but we'll replace the Azure Communication Services (ACS) calling mechanism (Solution 1) and the mocked calling (Solution 2) with an Alexa Skill. Users will interact with the application via Alexa-enabled devices (e.g., Amazon Echo, Echo Dot, or the Alexa app on a smartphone), making it more accessible and eliminating the need for a toll-free number or a web-based demo trigger.

Below is the updated step-by-step solution in Markdown format, integrating the Alexa Skills Kit while keeping the Azure services setup via the Azure Portal UI.

---

### **VoiceCard_AI_Solution_Using_Alexa_Integration_With_Azure_Portal_UI.md**

```markdown
# VoiceCard AI: Complete End-to-End Solution Using Alexa Integration and Azure Portal UI

This document provides a step-by-step solution for "VoiceCard AI," a voice-driven application designed for visually challenged users. The application allows users to interact with Amazon Alexa to generate a credit card quotation ID and handle follow-up questions via voice commands. Instead of calling a toll-free number or using a web-based demo, users can now say, "Alexa, open VoiceCard AI," to start the process. We'll build the application using a Java 21 Spring Boot backend, integrate it with Alexa using the Alexa Skills Kit (ASK), and set up Azure services using the **Azure Portal UI**.

## Key Features
- Users interact with the application by saying, "Alexa, open VoiceCard AI," on any Alexa-enabled device.
- The system guides users through the credit card quotation process using voice prompts.
- A quotation ID is generated by calling a mock Quotation API.
- Follow-up questions are handled during the same interaction.
- Ensures accessibility for visually challenged users with voice-only interaction.

## Prerequisites
- **Java 21** installed.
- **Maven** for building the Java project.
- **VS Code** or **IntelliJ** for coding.
- **Node.js** and **npm** for the mock API and Alexa Skill development.
- **PostgreSQL** for data storage.
- **Azure Account** with access to:
  - Azure Cognitive Services Speech Service for voice interaction (optional, as Alexa handles voice).
  - Azure Key Vault, Application Insights, and Azure AD B2C (optional).
- **Amazon Developer Account** to create an Alexa Skill.
- **Alexa-enabled device** (e.g., Amazon Echo, Echo Dot, or the Alexa app on a smartphone).

## Today's Date and Time
- **Date and Time:** 03:48 PM IST, Monday, June 02, 2025.

---

## Step 1: Set Up Your Development Environment

### 1.1 Verify Java 21
- Confirm Java 21 is installed:
  ```bash
  java -version
  ```
  Expected output:
  ```
  java version "21" 2023-09-19 LTS
  ```
- Set `JAVA_HOME`:
  - On Windows: `setx JAVA_HOME "C:\Program Files\Java\jdk-21" /M`
  - On macOS/Linux: Add to `~/.bashrc` or `~/.zshrc`:
    ```bash
    export JAVA_HOME=/path/to/jdk-21
    source ~/.bashrc
    ```
- Verify: `echo $JAVA_HOME`.

### 1.2 Install Other Tools
- **Maven**: Download from [apache.org](https://maven.apache.org/download.cgi), extract, and add to `PATH`. Verify: `mvn -version`.
- **VS Code/IntelliJ**: Install [VS Code](https://code.visualstudio.com/) or [IntelliJ IDEA](https://www.jetbrains.com/idea/). Add Java extensions if using VS Code.
- **Node.js and npm**: Install [Node.js](https://nodejs.org/). Verify: `node -v` and `npm -v`.
- **PostgreSQL**: Install [PostgreSQL](https://www.postgresql.org/download/). Set a password (e.g., `your-postgres-password`). Create a database:
  ```bash
  psql -U postgres
  CREATE DATABASE creditcard_db;
  \q
  ```
- **Alexa Developer Console**: Sign up for an Amazon Developer account at [developer.amazon.com](https://developer.amazon.com).

### 1.3 Set Up the Mock Quotation API
Create a mock API for generating quotation IDs:

In `mock-creditcard-api/server.js`:

```javascript
const express = require('express');
const app = express();
app.use(express.json());

app.post('/api/creditcard/apply', (req, res) => {
    const { name, income, phone } = req.body;
    const quotationId = `QUOT-${Math.random().toString(36).substring(2, 8)}`;
    res.json({ name, phone, quotationId });
});

app.listen(3000, () => console.log('Mock Quotation API running on port 3000'));
```

To set up:
1. Create a directory: `mock-creditcard-api`.
2. Initialize a Node.js project:
   ```bash
   cd mock-creditcard-api
   npm init -y
   npm install express
   ```
3. Save the code as `server.js`.
4. Start the API:
   ```bash
   node server.js
   ```

---

## Step 2: Set Up Azure Services Using Azure Portal UI

We’ll set up the necessary Azure services (Resource Group, Speech Service, Key Vault, Azure AD B2C, Application Insights) using the Azure Portal UI. Note that Azure Speech Service is optional since Alexa handles voice interaction, but we’ll include it for consistency with previous solutions.

### 2.1 Create an Azure Account
1. Go to [azure.com](https://azure.com) and sign up for a free account ($200 credit for 30 days).
2. Sign in to the Azure Portal at [portal.azure.com](https://portal.azure.com).

### 2.2 Set Up a Resource Group
1. In the Azure Portal, click **Create a resource** (or use the search bar and type "Resource group").
2. Click **Create** under "Resource group".
3. Fill in the details:
   - **Resource group:** `voicecard-rg`.
   - **Region:** East US.
4. Click **Review + create**, then **Create**.

### 2.3 Create a Speech Service (Optional)
1. In the Azure Portal, click **Create a resource**.
2. Search for **Speech** and select **Speech** under Azure Cognitive Services.
3. Click **Create**.
4. Fill in the details:
   - **Subscription:** Select your subscription.
   - **Resource group:** `voicecard-rg`.
   - **Region:** East US.
   - **Name:** `voicecard-speech`.
   - **Pricing tier:** Free F0 (for demo purposes; upgrade to a paid tier for production).
5. Click **Review + create**, then **Create**.
6. Once deployed, go to the resource:
   - Navigate to **Keys and Endpoint** in the left sidebar.
   - Note **Key 1** (e.g., `your-speech-key`) and **Location/Region** (e.g., `eastus`).

### 2.4 Create a Key Vault
1. In the Azure Portal, click **Create a resource**.
2. Search for **Key Vault** and select **Key Vault**.
3. Click **Create**.
4. Fill in the details:
   - **Subscription:** Select your subscription.
   - **Resource group:** `voicecard-rg`.
   - **Key vault name:** `voicecard-vault`.
   - **Region:** East US.
   - **Pricing tier:** Standard.
5. Click **Review + create**, then **Create**.
6. Once deployed, go to the Key Vault resource:
   - Navigate to **Secrets** in the left sidebar.
   - Click **+ Generate/Import**.
   - Create a secret:
     - **Name:** `speech-key`.
     - **Value:** `your-speech-key` (from Step 2.3).
   - Click **Create**.
7. Note the Key Vault URI:
   - Go to **Overview**.
   - Copy the **Vault URI** (e.g., `https://voicecard-vault.vault.azure.net/`).

### 2.5 Set Up Azure Active Directory B2C (Optional)
1. In the Azure Portal, click **Create a resource**.
2. Search for **Azure Active Directory B2C** and select it.
3. Click **Create**.
4. Choose **Create a new Azure AD B2C Tenant**:
   - **Tenant name:** `VoiceCardB2C`.
   - **Initial domain name:** `voicecardb2c`.
   - **Country/Region:** United States.
   - Click **Review + create**, then **Create**.
5. Once the tenant is created, link it to your subscription:
   - Go to **Azure Active Directory** in the Azure Portal.
   - Switch to the `VoiceCardB2C` directory.
   - Go to **App registrations** > **New registration**.
   - **Name:** `voicecard-app`.
   - **Redirect URI:** `http://localhost:8080/login/oauth2/code/azure`.
   - Click **Register**.
   - Note the **Application (client) ID**.
6. Create a client secret:
   - Go to **Certificates & secrets**.
   - Click **+ New client secret**.
   - **Description:** `voicecard-secret`.
   - Click **Add**.
   - Note the **Client Secret** value.

### 2.6 Create an Application Insights Resource (Optional)
1. In the Azure Portal, click **Create a resource**.
2. Search for **Application Insights** and select it.
3. Click **Create**.
4. Fill in the details:
   - **Subscription:** Select your subscription.
   - **Resource group:** `voicecard-rg`.
   - **Name:** `voicecard-insights`.
   - **Region:** East US.
   - **Resource Mode:** Classic.
5. Click **Review + create**, then **Create**.
6. Once deployed, go to the resource:
   - Navigate to **Overview**.
   - Note the **Instrumentation Key** (e.g., `your-instrumentation-key`).

---

## Step 3: Create the Alexa Skill

### 3.1 Create a New Alexa Skill
1. Go to the [Alexa Developer Console](https://developer.amazon.com/alexa/console/ask) and sign in.
2. Click **Create Skill**.
3. Fill in the details:
   - **Skill name:** `VoiceCard AI`.
   - **Default language:** English (US).
   - **Choose a model:** Custom.
   - **Hosting method:** Provision your own (we’ll host the backend on our Spring Boot application).
4. Click **Create Skill**.

### 3.2 Define the Interaction Model
1. In the Alexa Developer Console, go to **Build > Interaction Model > Intents**.
2. Create a custom intent for starting the quotation process:
   - Click **+ Add Intent**.
   - **Intent name:** `StartQuotationIntent`.
   - Add sample utterances:
     - "start quotation"
     - "generate a credit card quotation"
     - "begin quotation process"
   - Add slots for user inputs:
     - **Slot 1:**
       - **Name:** `userName`.
       - **Type:** `AMAZON.Person`.
       - Sample utterances: "my name is {userName}".
     - **Slot 2:**
       - **Name:** `phoneNumber`.
       - **Type:** `AMAZON.PhoneNumber`.
       - Sample utterances: "my phone number is {phoneNumber}".
     - **Slot 3:**
       - **Name:** `income`.
       - **Type:** `AMAZON.NUMBER`.
       - Sample utterances: "my income is {income} dollars".
3. Create a custom intent for follow-up questions:
   - Click **+ Add Intent**.
   - **Intent name:** `FollowUpIntent`.
   - Add sample utterances:
     - "yes I have a question"
     - "I have a follow-up question"
     - "tell me more"
   - Add a slot for the question:
     - **Name:** `question`.
     - **Type:** `AMAZON.SearchQuery`.
     - Sample utterances: "my question is {question}".
4. Create a custom intent to end the session:
   - Click **+ Add Intent**.
   - **Intent name:** `EndSessionIntent`.
   - Add sample utterances:
     - "no I don’t have any questions"
     - "end session"
     - "goodbye"
5. Save and build the model:
   - Click **Save Model**, then **Build Model**.

### 3.3 Set Up the Skill Endpoint
We’ll host the Alexa Skill backend on our Spring Boot application, so we need a public URL. For local testing, use `ngrok`.

1. **Install `ngrok`:**
   - Download and install [ngrok](https://ngrok.com/).
   - Start `ngrok` to expose your local server:
     ```bash
     ngrok http 8080
     ```
   - Note the public URL, e.g., `https://your-ngrok-subdomain.ngrok.io`.

2. In the Alexa Developer Console, go to **Build > Endpoint**.
3. Select **HTTPS** as the endpoint type.
4. Set the **Default Region** endpoint to: `https://your-ngrok-subdomain.ngrok.io/alexa`.
5. Set the SSL certificate type to **My development endpoint is a sub-domain of a domain that has a wildcard certificate from a certificate authority**.
6. Save the endpoint.

---

## Step 4: Create the Java Application with Alexa Integration

### 4.1 Project Structure
The project structure for the Spring Boot application (`voicecard-ai`) is as follows:

```
voicecard-ai/
├── pom.xml
├── src/
│   ├── main/
│   │   ├── java/
│   │   │   └── com/
│   │   │       └── voicecard/
│   │   │           ├── VoiceCardAiApplication.java
│   │   │           ├── config/
│   │   │           │   ├── AppInsightsConfig.java
│   │   │           │   └── SecurityConfig.java
│   │   │           ├── controller/
│   │   │           │   └── AlexaController.java
│   │   │           ├── model/
│   │   │           │   └── Application.java
│   │   │           ├── repository/
│   │   │           │   └── ApplicationRepository.java
│   │   │           ├── service/
│   │   │           │   ├── QuotationService.java
│   │   │           │   ├── ApplicationService.java
│   │   │           │   └── KeyVaultService.java
│   │   └── resources/
│   │       └── application.properties
└── mock-creditcard-api/
    └── server.js
```

**Note:** We’ve removed the `SpeechService`, `CallingService`, and `MockCallingService` since Alexa handles voice interaction and call simulation. We’ve also removed the `DemoController` and Thymeleaf template since the interaction is now through Alexa.

### 4.2 Create a Spring Boot Project
1. Go to [start.spring.io](https://start.spring.io/).
2. Fill in:
   - Project: Maven
   - Language: Java
   - Spring Boot: 3.2.5
   - Group: `com.voicecard`
   - Artifact: `voicecard-ai`
   - Java: 21
   - Dependencies: Add "Spring Web", "Spring Data JPA", "PostgreSQL Driver".
3. Generate, download, and open in your IDE.

### 4.3 `pom.xml`
The `pom.xml` file includes dependencies for Alexa Skills Kit, Key Vault, Application Insights, and Spring Security:

```xml
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>
    <groupId>com.voicecard</groupId>
    <artifactId>voicecard-ai</artifactId>
    <version>0.0.1-SNAPSHOT</version>
    <name>voicecard-ai</name>
    <description>VoiceCard AI project for credit card applications with Alexa integration</description>

    <parent>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-parent</artifactId>
        <version>3.2.5</version>
        <relativePath/>
    </parent>

    <properties>
        <java.version>21</java.version>
    </properties>

    <dependencies>
        <!-- Spring Boot Starters -->
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-web</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-data-jpa</artifactId>
        </dependency>
        <dependency>
            <groupId>org.postgresql</groupId>
            <artifactId>postgresql</artifactId>
            <scope>runtime</scope>
        </dependency>

        <!-- Alexa Skills Kit SDK -->
        <dependency>
            <groupId>com.amazon.alexa</groupId>
            <artifactId>ask-sdk</artifactId>
            <version>2.70.0</version>
        </dependency>

        <!-- Azure Key Vault -->
        <dependency>
            <groupId>com.azure</groupId>
            <artifactId>azure-identity</artifactId>
            <version>1.12.0</version>
        </dependency>
        <dependency>
            <groupId>com.azure</groupId>
            <artifactId>azure-security-keyvault-secrets</artifactId>
            <version>4.8.0</version>
        </dependency>

        <!-- Application Insights -->
        <dependency>
            <groupId>com.microsoft.applicationinsights</groupId>
            <artifactId>applicationinsights-core</artifactId>
            <version>3.5.1</version>
        </dependency>

        <!-- HTTP Client for Quotation API -->
        <dependency>
            <groupId>org.apache.httpcomponents</groupId>
            <artifactId>httpclient</artifactId>
            <version>4.5.14</version>
        </dependency>

        <!-- Spring Security for Azure AD B2C -->
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-security</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.security</groupId>
            <artifactId>spring-security-oauth2-client</artifactId>
        </dependency>

        <!-- JSON Processing -->
        <dependency>
            <groupId>org.json</groupId>
            <artifactId>json</artifactId>
            <version>20231013</version>
        </dependency>
    </dependencies>

    <build>
        <plugins>
            <plugin>
                <groupId>org.springframework.boot</groupId>
                <artifactId>spring-boot-maven-plugin</artifactId>
            </plugin>
        </plugins>
    </build>
</project>
```

**Note:** We’ve removed dependencies for Azure Speech SDK and ACS since Alexa handles voice interaction.

### 4.4 `application.properties`
The `application.properties` file contains configurations for the backend:

```properties
# PostgreSQL
spring.datasource.url=jdbc:postgresql://localhost:5432/creditcard_db
spring.datasource.username=postgres
spring.datasource.password=your-postgres-password
spring.jpa.hibernate.ddl-auto=update

# Azure Key Vault
azure.keyvault.uri=https://voicecard-vault.vault.azure.net/
azure.keyvault.client-id=your-adb2c-client-id
azure.keyvault.client-secret=your-adb2c-client-secret
azure.keyvault.tenant-id=your-adb2c-tenant-id

# Application Insights
applicationinsights.instrumentation-key=your-instrumentation-key

# Mock Quotation API
creditcard.api.url=http://localhost:3000/api/creditcard/apply

# Spring Security OAuth2 for Azure AD B2C
spring.security.oauth2.client.registration.azure.client-id=your-adb2c-client-id
spring.security.oauth2.client.registration.azure.client-secret=your-adb2c-client-secret
spring.security.oauth2.client.registration.azure.scope=openid,profile
spring.security.oauth2.client.registration.azure.authorization-grant-type=authorization_code
spring.security.oauth2.client.registration.azure.redirect-uri=http://localhost:8080/login/oauth2/code/azure
spring.security.oauth2.client.provider.azure.authorization-uri=https://voicecardb2c.b2clogin.com/voicecardb2c.onmicrosoft.com/B2C_1_signup_signin/oauth2/v2.0/authorize
spring.security.oauth2.client ⟐provider.azure.token-uri=https://voicecardb2c.b2clogin.com/voicecardb2c.onmicrosoft.com/B2C_1_signup_signin/oauth2/v2.0/token
spring.security.oauth2.client.provider.azure.user-info-uri=https://graph.microsoft.com/oidc/userinfo
spring.security.oauth2.client.provider.azure.user-name-attribute=preferred_username
```

Replace placeholders with values from Step 2.

### 4.5 `VoiceCardAiApplication.java`
The main application class to start the Spring Boot application:

In `src/main/java/com/voicecard/VoiceCardAiApplication.java`:

```java
package com.voicecard;

import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;

@SpringBootApplication
public class VoiceCardAiApplication {
    public static void main(String[] args) {
        SpringApplication.run(VoiceCardAiApplication.class, args);
    }
}
```

### 4.6 `Application.java` (Model)
The data model for storing application details:

In `src/main/java/com/voicecard/model/Application.java`:

```java
package com.voicecard.model;

import jakarta.persistence.Entity;
import jakarta.persistence.GeneratedValue;
import jakarta.persistence.GenerationType;
import jakarta.persistence.Id;

@Entity
public class Application {
    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;
    private String name;
    private String phone;
    private double income;
    private String decision;

    // Getters and Setters
    public Long getId() { return id; }
    public void setId(Long id) { this.id = id; }
    public String getName() { return name; }
    public void setName(String name) { this.name = name; }
    public String getPhone() { return phone; }
    public void setPhone(String phone) { this.phone = phone; }
    public double getIncome() { return income; }
    public void setIncome(double income) { this.income = income; }
    public String getDecision() { return decision; }
    public void setDecision(String decision) { this.decision = decision; }
}
```

### 4.7 `ApplicationRepository.java`
The JPA repository for database operations:

In `src/main/java/com/voicecard/repository/ApplicationRepository.java`:

```java
package com.voicecard.repository;

import com.voicecard.model.Application;
import org.springframework.data.jpa.repository.JpaRepository;

public interface ApplicationRepository extends JpaRepository<Application, Long> {
}
```

### 4.8 `QuotationService.java`
The service to generate a quotation ID by calling the mock Quotation API:

In `src/main/java/com/voicecard/service/QuotationService.java`:

```java
package com.voicecard.service;

import org.apache.http.client.methods.HttpPost;
import org.apache.http.entity.StringEntity;
import org.apache.http.impl.client.CloseableHttpClient;
import org.apache.http.impl.client.HttpClients;
import org.apache.http.util.EntityUtils;
import org.json.JSONObject;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.stereotype.Service;

import java.util.UUID;

@Service
public class QuotationService {
    @Value("${creditcard.api.url}")
    private String quotationApiUrl;

    public String generateQuotationId(String name, String phone, double income) throws Exception {
        try (var client = HttpClients.createDefault()) {
            var post = new HttpPost(quotationApiUrl);
            var json = new JSONObject();
            json.put("name", name);
            json.put("phone", phone);
            json.put("income", income);
            post.setEntity(new StringEntity(json.toString()));
            post.setHeader("Content-Type", "application/json");
            var response = EntityUtils.toString(client.execute(post).getEntity());
            var responseJson = new JSONObject(response);
            // Mock a quotation ID
            String quotationId = "QUOT-" + UUID.randomUUID().toString().substring(0, 8);
            return quotationId;
        }
    }
}
```

### 4.9 `ApplicationService.java`
The service to manage the application process, now adapted for Alexa responses:

In `src/main/java/com/voicecard/service/ApplicationService.java`:

```java
package com.voicecard.service;

import com.voicecard.model.Application;
import com.voicecard.repository.ApplicationRepository;
import com.microsoft.applicationinsights.TelemetryClient;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Service;

@Service
public class ApplicationService {
    private final QuotationService quotationService;
    private final ApplicationRepository repository;
    @Autowired
    private TelemetryClient telemetryClient;

    public ApplicationService(QuotationService quotationService, ApplicationRepository repository) {
        this.quotationService = quotationService;
        this.repository = repository;
    }

    public String processApplication(String name, String phone, double income) throws Exception {
        var app = new Application();
        app.setName(name);
        app.setPhone(phone);
        app.setIncome(income);

        // Generate quotation ID
        telemetryClient.trackEvent("Generating quotation ID for user: " + name);
        var quotationId = quotationService.generateQuotationId(name, phone, income);
        app.setDecision(quotationId);

        // Save to database
        repository.save(app);

        return quotationId;
    }

    public void logFollowUpQuestion(String question) {
        telemetryClient.trackEvent("Follow-up question from user: " + question);
    }
}
```

**Note:** Since Alexa handles voice interaction, we’ve removed speech synthesis and recognition logic. The service now focuses on business logic and returns text responses for Alexa to speak.

### 4.10 `KeyVaultService.java`
The service to retrieve secrets from Azure Key Vault:

In `src/main/java/com/voicecard/service/KeyVaultService.java`:

```java
package com.voicecard.service;

import com.azure.identity.DefaultAzureCredentialBuilder;
import com.azure.security.keyvault.secrets.SecretClient;
import com.azure.security.keyvault.secrets.SecretClientBuilder;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.stereotype.Service;

@Service
public class KeyVaultService {
    private final SecretClient secretClient;

    public KeyVaultService(@Value("${azure.keyvault.uri}") String keyVaultUri) {
        this.secretClient = new SecretClientBuilder()
                .vaultUrl(keyVaultUri)
                .credential(new DefaultAzureCredentialBuilder().build())
                .buildClient();
    }

    public String getSecret(String secretName) {
        return secretClient.getSecret(secretName).getValue();
    }
}
```

### 4.11 `AlexaController.java`
The controller to handle Alexa requests:

In `src/main/java/com/voicecard/controller/AlexaController.java`:

```java
package com.voicecard.controller;

import com.amazon.ask.dispatcher.request.handler.HandlerInput;
import com.amazon.ask.dispatcher.request.handler.RequestHandler;
import com.amazon.ask.model.*;
import com.amazon.ask.request.Predicates;
import com.amazon.ask.servlet.SkillServlet;
import com.voicecard.service.ApplicationService;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.web.servlet.ServletRegistrationBean;
import org.springframework.context.annotation.Bean;
import org.springframework.web.bind.annotation.RestController;

import java.util.HashMap;
import java.util.Map;
import java.util.Optional;

@RestController
public class AlexaController {

    @Autowired
    private ApplicationService applicationService;

    private final Map<String, Map<String, String>> sessionData = new HashMap<>();

    @Bean
    public ServletRegistrationBean<SkillServlet> alexaServlet() {
        SkillServlet skillServlet = new SkillServlet(new VoiceCardAiSkill());
        return new ServletRegistrationBean<>(skillServlet, "/alexa");
    }

    // Handler for LaunchRequest
    public class LaunchRequestHandler implements RequestHandler {
        @Override
        public boolean canHandle(HandlerInput input) {
            return input.matches(Predicates.requestType(LaunchRequest.class));
        }

        @Override
        public Optional<Response> handle(HandlerInput input) {
            String sessionId = input.getRequestEnvelope().getSession().getSessionId();
            sessionData.put(sessionId, new HashMap<>());
            String speechText = "Welcome to VoiceCard AI. This is an automated system to help you generate a credit card quotation ID. Please say your name.";
            return input.getResponseBuilder()
                    .withSpeech(speechText)
                    .withReprompt("Please say your name.")
                    .build();
        }
    }

    // Handler for StartQuotationIntent
    public class StartQuotationIntentHandler implements RequestHandler {
        @Override
        public boolean canHandle(HandlerInput input) {
            return input.matches(Predicates.intentName("StartQuotationIntent"));
        }

        @Override
        public Optional<Response> handle(HandlerInput input) {
            String sessionId = input.getRequestEnvelope().getSession().getSessionId();
            Map<String, String> userData = sessionData.getOrDefault(sessionId, new HashMap<>());

            Intent intent = ((IntentRequest) input.getRequest()).getIntent();
            Map<String, Slot> slots = intent.getSlots();

            // Get name if provided, else prompt
            Slot nameSlot = slots.get("userName");
            if (nameSlot != null && nameSlot.getValue() != null) {
                userData.put("name", nameSlot.getValue());
            } else if (!userData.containsKey("name")) {
                return input.getResponseBuilder()
                        .withSpeech("Please say your name.")
                        .withReprompt("I didn’t catch your name. Please say your name.")
                        .build();
            }

            // Get phone number if provided, else prompt
            if (userData.containsKey("name") && !userData.containsKey("phone")) {
                return input.getResponseBuilder()
                        .withSpeech("Please say your phone number, one digit at a time, for example, 1 2 3 4 5 6 7 8 9 0.")
                        .withReprompt("Please say your phone number.")
                        .build();
            }

            Slot phoneSlot = slots.get("phoneNumber");
            if (phoneSlot != null && phoneSlot.getValue() != null) {
                String phone = phoneSlot.getValue().replaceAll("[^0-9]", "");
                userData.put("phone", phone);
            } else if (!userData.containsKey("phone")) {
                return input.getResponseBuilder()
                        .withSpeech("Please say your phone number, one digit at a time.")
                        .withReprompt("I didn’t catch your phone number. Please say your phone number.")
                        .build();
            }

            // Get income if provided, else prompt
            if (userData.containsKey("phone") && !userData.containsKey("income")) {
                return input.getResponseBuilder()
                        .withSpeech("Please say your annual income in dollars, for example, 50 thousand.")
                        .withReprompt("Please say your annual income.")
                        .build();
            }

            Slot incomeSlot = slots.get("income");
            if (incomeSlot != null && incomeSlot.getValue() != null) {
                double income = parseIncome(incomeSlot.getValue());
                userData.put("income", String.valueOf(income));

                // All data collected, generate quotation ID
                try {
                    String name = userData.get("name");
                    String phone = userData.get("phone");
                    double parsedIncome = Double.parseDouble(userData.get("income"));
                    String quotationId = applicationService.processApplication(name, phone, parsedIncome);

                    userData.put("quotationId", quotationId);
                    sessionData.put(sessionId, userData);

                    return input.getResponseBuilder()
                            .withSpeech("Thank you, " + name + ". Your credit card quotation ID is " + quotationId + ". Please note this down. Do you have any follow-up questions about your quotation? Please say yes or no.")
                            .withReprompt("Do you have any follow-up questions? Please say yes or no.")
                            .build();
                } catch (Exception e) {
                    return input.getResponseBuilder()
                            .withSpeech("Sorry, there was an error processing your request. Please try again.")
                            .withReprompt("Please try again.")
                            .build();
                }
            }

            return input.getResponseBuilder()
                    .withSpeech("Please say your annual income in dollars.")
                    .withReprompt("I didn’t catch your income. Please say your annual income.")
                    .build();
        }

        private double parseIncome(String incomeStr) {
            incomeStr = incomeStr.toLowerCase().replaceAll("[^0-9\\s]", "");
            if (incomeStr.contains("thousand")) {
                var number = Double.parseDouble(incomeStr.replace("thousand", "").trim());
                return number * 1000;
            }
            return Double.parseDouble(incomeStr.trim());
        }
    }

    // Handler for FollowUpIntent
    public class FollowUpIntentHandler implements RequestHandler {
        @Override
        public boolean canHandle(HandlerInput input) {
            return input.matches(Predicates.intentName("FollowUpIntent"));
        }

        @Override
        public Optional<Response> handle(HandlerInput input) {
            Intent intent = ((IntentRequest) input.getRequest()).getIntent();
            Map<String, Slot> slots = intent.getSlots();
            Slot questionSlot = slots.get("question");

            if (questionSlot != null && questionSlot.getValue() != null) {
                String question = questionSlot.getValue();
                applicationService.logFollowUpQuestion(question);
                return input.getResponseBuilder()
                        .withSpeech("Thank you for your question: " + question + ". A customer care representative will follow up with you soon. Thank you for using VoiceCard AI. Goodbye!")
                        .withShouldEndSession(true)
                        .build();
            }

            return input.getResponseBuilder()
                    .withSpeech("Please state your question.")
                    .withReprompt("I didn’t catch your question. Please state your question.")
                    .build();
        }
    }

    // Handler for EndSessionIntent
    public class EndSessionIntentHandler implements RequestHandler {
        @Override
        public boolean canHandle(HandlerInput input) {
            return input.matches(Predicates.intentName("EndSessionIntent"));
        }

        @Override
        public Optional<Response> handle(HandlerInput input) {
            String sessionId = input.getRequestEnvelope().getSession().getSessionId();
            sessionData.remove(sessionId);
            return input.getResponseBuilder()
                    .withSpeech("Thank you for using VoiceCard AI. Goodbye!")
                    .withShouldEndSession(true)
                    .build();
        }
    }

    // Skill configuration
    public class VoiceCardAiSkill extends com.amazon.ask.Skill {
        public VoiceCardAiSkill() {
            super();
            addRequestHandlers(
                    new LaunchRequestHandler(),
                    new StartQuotationIntentHandler(),
                    new FollowUpIntentHandler(),
                    new EndSessionIntentHandler()
            );
        }
    }
}
```

**Note:** The `AlexaController` handles Alexa requests and responses, maintaining session state using a simple `sessionData` map. It guides the user through the quotation process and handles follow-up questions, similar to the previous solutions, but now through Alexa’s voice interface.

### 4.12 `AppInsightsConfig.java`
The configuration for Application Insights:

In `src/main/java/com/voicecard/config/AppInsightsConfig.java`:

```java
package com.voicecard.config;

import com.microsoft.applicationinsights.TelemetryClient;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

@Configuration
public class AppInsightsConfig {
    @Value("${applicationinsights.instrumentation-key}")
    private String instrumentationKey;

    @Bean
    public TelemetryClient telemetryClient() {
        TelemetryClient client = new TelemetryClient();
        client.getContext().setInstrumentationKey(instrumentationKey);
        return client;
    }
}
```

### 4.13 `SecurityConfig.java`
The security configuration for Azure AD B2C:

In `src/main/java/com/voicecard/config/SecurityConfig.java`:

```java
package com.voicecard.config;

import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.security.config.annotation.web.builders.HttpSecurity;
import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;
import org.springframework.security.web.SecurityFilterChain;

@Configuration
@EnableWebSecurity
public class SecurityConfig {

    @Bean
    public SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception {
        http
            .authorizeHttpRequests(auth -> auth
                .requestMatchers("/alexa").permitAll() // Allow Alexa requests
                .anyRequest().authenticated()
            )
            .oauth2Login();
        return http.build();
    }
}
```

---

## Step 5: Test the Application

### 5.1 Start the Mock API
```bash
cd mock-creditcard-api
node server.js
```

### 5.2 Start the Spring Boot Application
```bash
cd voicecard-ai
mvn spring-boot:run
```

### 5.3 Test the Alexa Skill
1. **Enable the Skill:**
   - In the Alexa Developer Console, go to **Test**.
   - Enable testing for the skill by selecting **Development** in the dropdown.
2. **Test Using an Alexa-Enabled Device or Simulator:**
   - On an Alexa-enabled device (e.g., Echo Dot) or in the Alexa Developer Console’s test simulator, say: "Alexa, open VoiceCard AI."
   - Alexa will respond: "Welcome to VoiceCard AI. This is an automated system to help you generate a credit card quotation ID. Please say your name."
   - Respond with your name, e.g., "My name is John."
   - Alexa will prompt: "Please say your phone number, one digit at a time, for example, 1 2 3 4 5 6 7 8 9 0."
   - Respond with your phone number, e.g., "1 2 3 4 5 6 7 8 9 0."
   - Alexa will prompt: "Please say your annual income in dollars, for example, 50 thousand."
   - Respond with your income, e.g., "My income is 50 thousand dollars."
   - Alexa will respond with the quotation ID: "Thank you, John. Your credit card quotation ID is QUOT-XXXXXX. Please note this down. Do you have any follow-up questions about your quotation? Please say yes or no."
   - If you say "yes," Alexa will prompt: "Please state your question." Respond with your question, and Alexa will confirm it’s logged.
   - If you say "no," Alexa will end the session: "Thank you for using VoiceCard AI. Goodbye!"
3. **Verify Database and Monitoring:**
   - Check the database:
     ```bash
     psql -U postgres -d creditcard_db
     SELECT * FROM application;
     ```
   - Check Application Insights in the Azure Portal for logs (e.g., telemetry events for quotation generation and follow-up questions).

---

## Step 6: Prepare for Hackathon Presentation

### 6.1 Demonstrate the Flow
- Use an Alexa-enabled device (e.g., Echo Dot) or the Alexa app on your smartphone.
- Say: "Alexa, open VoiceCard AI."
- Follow the voice prompts to provide your name, phone number, income, and follow-up questions.
- Highlight how the system is accessible for visually challenged users with clear, voice-only prompts.
- Show the database entries to confirm the quotation ID was saved.
- Display Application Insights logs to show telemetry events.

### 6.2 Explain the Alexa Integration
- Mention that the application now uses Amazon Alexa instead of Azure Communication Services or a mocked calling service.
- Explain that users can interact with the application on any Alexa-enabled device, making it more accessible and eliminating the need for a toll-free number or web-based demo.
- Highlight that the backend logic (quotation generation, database storage) remains the same, but the interaction is now fully voice-driven through Alexa.

---

## Accessibility Considerations

- **Voice-Only Interaction:** The entire process is voice-driven via Alexa, with clear, slow prompts to assist visually challenged users.
- **Error Handling:** The system includes basic input parsing (e.g., for phone numbers and income) to handle speech recognition errors.
- **Follow-Up Support:** Users can ask follow-up questions, which are logged for later follow-up by a representative.

---

## Summary

- Built a voice-driven application for visually challenged users to generate credit card quotation IDs using Amazon Alexa.
- Integrated the application with Alexa using the Alexa Skills Kit, allowing users to interact by saying, "Alexa, open VoiceCard AI."
- Set up Azure services using the Azure Portal UI, replacing Azure CLI commands.
- Used a Java 21 Spring Boot backend to handle business logic, quotation generation, and database storage.
- Ensured accessibility with clear, voice-only prompts and error handling, now leveraging Alexa’s natural language processing capabilities.

This solution is now fully tailored for a hackathon demo, providing a seamless voice-driven experience through Alexa while maintaining the core functionality of the previous solutions.
```
---

### **Key Changes for Alexa Integration**

- **Alexa Skills Kit Integration:** The application now uses the Alexa Skills Kit to handle voice interactions, replacing Azure Communication Services (Solution 1) and the mocked calling service (Solution 2). Users interact by saying, "Alexa, open VoiceCard AI," on any Alexa-enabled device.
- **Removed Speech and Calling Services:** Since Alexa handles voice interaction (speech synthesis and recognition), we’ve removed `SpeechService`, `CallingService`, and `MockCallingService`. The `ApplicationService` now focuses on business logic and returns text for Alexa to speak.
- **Alexa Controller:** Added `AlexaController` to handle Alexa requests and responses, managing the conversational flow (e.g., prompting for name, phone, income, and follow-up questions) using intents and slots defined in the Alexa Skill.
- **Session Management:** Used a simple `sessionData` map to maintain user data (name, phone, income) across the conversation, as Alexa skills are stateless by default.
- **Azure Portal UI:** Retained the Azure Portal UI setup for Azure services, ensuring consistency with your previous request.

### **Benefits of Using Alexa**

- **Wider Accessibility:** Users can interact with the application on any Alexa-enabled device (e.g., Echo, Echo Dot, or the Alexa app), making it more accessible for visually challenged users without needing a phone number or web interface.
- **Natural Voice Interaction:** Alexa’s natural language processing provides a more intuitive voice-driven experience compared to the previous ACS or mocked calling approaches.
- **Scalability:** The Alexa Skills Kit allows for easy extension of functionality (e.g., adding more intents or integrating with other Alexa features like cards or notifications).

This solution leverages Alexa’s capabilities to provide a seamless, voice-only experience while maintaining the core functionality of generating credit card quotation IDs and handling follow-up questions.